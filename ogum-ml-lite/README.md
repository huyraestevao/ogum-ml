# Ogum ML Lite

[![CI](https://github.com/huyraestevao/ogum-ml/actions/workflows/ci.yml/badge.svg)](https://github.com/huyraestevao/ogum-ml/actions/workflows/ci.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Open In Colab](https://colab.research.googleusercontent.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huyraestevao/ogum-ml/blob/main/ogum-ml-lite/notebooks/ogum_ml_demo.ipynb)

Bootstrap do toolkit **Ogum ML Lite** para c√°lculos de Œ∏(Ea), derivadas
cin√©ticas, ajustes Arrhenius e Master Sintering Curves (MSC) compat√≠veis com o
ecossistema Ogum 6.4. O objetivo √© disponibilizar um pacote Python leve, f√°cil
de usar em Google Colab e pronto para integra√ß√µes com pipelines de ML.

## Vis√£o geral

- **Pr√©-processamento completo**: mapeamento autom√°tico de planilhas
  (.csv/.xls/.xlsx), normaliza√ß√£o de unidades e metadados obrigat√≥rios
  (`composition`, `technique`).
- **Derivadas e Arrhenius**: suaviza√ß√£o Savitzky‚ÄìGolay/m√©dia m√≥vel, c√°lculo de
  `dy/dt`, `dT/dt`, raz√µes Arrhenius e ajustes globais/por est√°gio.
- **Œ∏(Ea) r√°pido**: c√°lculo direto a partir de ensaios de sinteriza√ß√£o via
  `OgumLite.compute_theta_table` ou CLI.
- **MSC robusta**: m√©trica segmentada (55‚Äì70‚Äì90%) para avaliar o colapso das
  curvas por amostra.
- **Segmenta√ß√£o autom√°tica**: CLI `segmentation` com limiares 55‚Äì70‚Äì90% ou
  modo data-driven simples.
- **Mudan√ßa de mecanismo**: ajuste piecewise linear com AIC/BIC via
  `cli mechanism`.
- **Compatibilidade**: nomes de colunas (`sample_id`, `time_s`, `temp_C`,
  `rho_rel`) alinhados com Ogum 6.4 e notebooks do reposit√≥rio
  [ogumsoftware](https://github.com/huyraestevao/ogumsoftware).
- **Pronto para ML**: m√≥dulo `features` com engenharia global e stage-aware,
  integra√ß√£o com `theta_msc` e `ml_hooks` para pipelines supervisionados.

## Frontend Evolutivo (Fase 8)

O frontend agora usa uma arquitetura modular com design system leve, theming
din√¢mico, i18n e camada de servi√ßos compartilhada.

## Telemetria e Experimentos (Fase 10)

### Telemetria opcional

- Opt-in local pela sidebar ou via `OGUML_TELEMETRY=1`.
- Somente eventos t√©cnicos (nome da etapa, dura√ß√£o, variante A/B, acertos de cache) s√£o gravados em `workspace/telemetry.jsonl`.
- Agregue e limpe m√©tricas com o utilit√°rio:

```bash
python -m app.services.cli_tools telemetry aggregate --file workspace/telemetry.jsonl --out telemetry_summary.json
python -m app.services.cli_tools telemetry clean --file workspace/telemetry.jsonl
```

### Experimentos A/B de UX

- Experimentos ativos: `wizard_vs_tabs`, `msc_controls_layout`, `run_buttons_position`.
- Atribui√ß√£o sticky por sess√£o com coleta autom√°tica nas a√ß√µes do wizard.
- Exporte contagens por variante:

```bash
python -m app.services.cli_tools ab export --file workspace/telemetry.jsonl --out ab_summary.json
```

### Temas personalizados

- Temas base em `app/config/themes/` (`base.yaml`, `dark.yaml`, `custom.example.yaml`).
- Fa√ßa upload de um YAML pela sidebar ou adicione o arquivo ao diret√≥rio para disponibiliz√°-lo.
- A fun√ß√£o `get_theme(dark, override)` mescla overrides com o tema base.

### Perfis de execu√ß√£o por t√©cnica

- Perfis YAML em `app/config/profiles/` (`conventional`, `fs_uhs`, `sps`).
- Sele√ß√£o pela sidebar aplica presets de Ea, m√©tricas MSC, features el√©tricas etc.
- O diff aplicado √© exibido como JSON resumido logo abaixo da sele√ß√£o.

### Cache e Performance

- Cache em disco por hash de entradas idempotentes (prep, features, MSC) em `workspace/.cache/`.
- Instrumenta√ß√£o com `@profile_step` gera dura√ß√£o/mem√≥ria, exibidos tanto no log quanto na telemetria.
- Inspecione ou limpe o cache via CLI:

```bash
python -m app.services.cli_tools cache stats --dir workspace/.cache
python -m app.services.cli_tools cache purge --dir workspace/.cache
```

### Streamlit (painel principal)

```bash
streamlit run app/streamlit_app.py
```

- **Layout modular**: shell comum em `app/design/layout.py` com sidebar para
  workspace/preset, header com toggle de tema e export, e p√°ginas em
  `app/pages/*.py`.
- **Theming**: `app/design/theme.py` exp√µe `get_theme(dark)` para claro/escuro;
  altern√¢ncia em tempo real sem recarregar o app.
- **i18n**: seletor de idioma (pt/en) alimenta `app/i18n/translate.py` com
  cat√°logos JSON; textos respondem imediatamente √† troca de locale.
- **Services**: todas as a√ß√µes orquestram a CLI via `app/services/run_cli.py`
  (tenacity + logs + telemetria) reaproveitando `ogum_lite.ui.orchestrator`.
- **UX**: toasts, valida√ß√µes, barras de progresso e previews foram integrados √†s
  p√°ginas de Prep, Features, Œ∏/MSC, Segmenta√ß√£o, Mecanismo, ML e Export.
- **Estado**: `app/services/state.py` centraliza `session_state`, workspace e
  registro de artefatos; telemetria opcional (`OGUML_TELEMETRY=0` desliga).

### Modo guiado (Wizard)

- Dispon√≠vel no menu lateral como primeira op√ß√£o (`Modo guiado`).
- Bloqueia a navega√ß√£o enquanto os artefatos obrigat√≥rios n√£o estiverem prontos e exibe toasts `[ok]/[warn]`.
- Cada etapa reutiliza os servi√ßos existentes (`run_cli`) com tooltips, descri√ß√µes acess√≠veis e persist√™ncia em `session_state`.
- Documenta√ß√£o completa de UX e microc√≥pia em [`docs/DESIGN_SPEC_UX.md`](docs/DESIGN_SPEC_UX.md) e [`docs/MICROCOPY_*.yaml`](docs).

#### Como estender com nova p√°gina

1. Crie `app/pages/page_nova.py` com `render(translator: I18N) -> None`.
2. Use componentes do design system (`card`, `alert`, `toolbar`) e servi√ßos.
3. Registre a p√°gina em `PAGES` dentro de `app/streamlit_app.py`.
4. Adicione microc√≥pia em `docs/MICROCOPY_*.yaml` e tradu√ß√µes em `app/i18n/locales/*.json`.
5. Rode `python -m app.services.i18n_lint` e `pytest -q` para garantir cobertura.

#### Qualidade cont√≠nua

- `python -m app.services.i18n_lint` garante paridade de chaves pt/en.
- `python -m app.services.linkcheck` valida links internos do README e da Design Spec.
- `pytest -q` cobre o fluxo guiado, helpers de acessibilidade e integra√ß√µes b√°sicas.

### Gradio (fallback)

```bash
python app/gradio_app.py
```

Interface Blocks compacta que reutiliza `app/services/run_cli.py` para rodar o
pipeline e gerar o ZIP com os artefatos do workspace.

## Fase 11 ‚Äî Experimenta√ß√£o Avan√ßada

### Modelos opcionais

Os novos benchmarks suportam modelos adicionais de gradient boosting sem
depender deles por padr√£o. Instale apenas o que precisar:

```bash
pip install "ogum-ml[lgbm]"  # LightGBM
pip install "ogum-ml[cat]"   # CatBoost
pip install "ogum-ml[xgb]"   # XGBoost
```

Sem essas extras, os modelos continuam dispon√≠veis via Random Forest.

### Benchmark padronizado

Use `ml bench` para executar a matriz `targets √ó feature_sets √ó modelos`, com
GroupKFold por `sample_id` e pipelines consistentes (StandardScaler +
OneHotEncoder + estimador). Um exemplo de classifica√ß√£o:

```bash
python -m ogum_lite.cli ml bench \
  --table features.csv \
  --task cls \
  --targets technique \
  --feature-sets basic="heating_rate_med_C_per_s,T_max_C,y_final,t_to_90pct_s" \
                  theta="theta_Ea_200kJ,theta_Ea_300kJ,theta_Ea_400kJ" \
  --models rf,lgbm,cat,xgb \
  --group-col sample_id \
  --outdir artifacts/bench_cls
```

Cada combina√ß√£o gera uma pasta `<outdir>/<target>/<feature_set>/<model>/` com
`model.joblib`, `feature_cols.json`, `target.json`, `cv_metrics.json`,
`model_card.json` e `training_log.json`. As m√©tricas consolidadas ficam em
`bench_results.csv`.

### Compara√ß√£o e ranking

Depois de rodar o benchmark, gere o resumo com `ml compare`:

```bash
python -m ogum_lite.cli ml compare \
  --bench-csv artifacts/bench_cls/bench_results.csv \
  --task cls \
  --outdir artifacts/bench_cls
```

O comando cria `bench_summary.csv` (ranking por alvo/conjunto de features) e
`ranking.png` (m√©dia geral). Modelos indispon√≠veis s√£o ignorados automaticamente
com aviso `[skip]`.

> üí° Para execu√ß√µes r√°pidas em datasets grandes, reduza `n_estimators` ajustando
> os par√¢metros ao instanciar os pipelines (ex.: `--models rf` para testes
> r√°pidos ou adaptando o c√≥digo/factory antes da rodada final).

## Instala√ß√£o

```bash
conda env create -f environment.yml
conda activate ogum-ml-lite

pip install -e .[dev]
```

## Formato de dados (long)

Os ensaios devem estar em formato *long* com uma linha por instante de tempo e
metadados m√≠nimos:

| Coluna       | Descri√ß√£o                                        |
|--------------|--------------------------------------------------|
| `sample_id`  | Identificador √∫nico da amostra/ensaio             |
| `time`       | Tempo em segundos ou minutos (`time_s`/`time_min`)|
| `temp`       | Temperatura em ¬∞C ou K (`temp_C`/`temp_K`)        |
| `response`   | `rho_rel`/`shrinkage_rel` (0‚Äì1)                   |
| `composition`| Legenda da liga/composi√ß√£o                       |
| `technique`  | Rota de sinteriza√ß√£o (dropdown Ogum 6.4)          |

Outras colunas (press√£o, est√°gio, etc.) podem ser preservadas ‚Äî o mapeamento
autom√°tico permite alinhar planilhas heterog√™neas aos nomes can√¥nicos.

## Pipeline (Fase 3.1)

Fluxo recomendado:

1. **Importar planilha** (`io map`): inferir/ajustar o mapeamento de colunas e
   normalizar unidades.
2. **Pr√©-processar** (`preprocess derive`): aplicar o mapeamento, suavizar e
   gerar as derivadas (`dy/dt`, `dT/dt`, `T¬∑dy/dt`, ...).
3. **Arrhenius** (`arrhenius fit`): calcular Ea global, por est√°gios padr√£o
   (55‚Äì70%, 70‚Äì90%) e exportar a regress√£o `ln(T¬∑dy/dt)` vs `1/T`.
4. **Feature store** (`features build`): consolidar m√©tricas globais + por
   est√°gio + Ea Arrhenius + Œ∏(Ea) opcionais para ML.
5. **MSC/Œ∏** (`msc`, `theta`): continuar com os m√≥dulos cl√°ssicos se necess√°rio.

Outras colunas (press√£o, est√°gio, etc.) podem ser preservadas ‚Äî apenas os
nomes acima s√£o obrigat√≥rios para o pipeline m√≠nimo.

## Uso r√°pido (CLI)

```bash
# 1) Inferir mapeamento e salvar JSON
python -m ogum_lite.cli io map \
  --input data/ensaio.xlsx \
  --out artifacts/mapping.json \
  --edit

# 2) Aplicar mapeamento + derivadas
python -m ogum_lite.cli preprocess derive \
  --input data/ensaio.xlsx \
  --map artifacts/mapping.json \
  --smooth savgol \
  --out exports/derivatives.csv

# 3) Ajustes Arrhenius (global + est√°gios)
python -m ogum_lite.cli arrhenius fit \
  --input exports/derivatives.csv \
  --stages "0.55-0.70,0.70-0.90" \
  --out exports/arrhenius.csv \
  --png exports/arrhenius.png

# 4) Feature store stage-aware + Œ∏(Ea)
python -m ogum_lite.cli features build \
  --input exports/derivatives.csv \
  --stages "0.55-0.70,0.70-0.90" \
  --theta-ea "200,250,300" \
  --out exports/feature_store.csv

# 5) Segmenta√ß√£o autom√°tica (fixed/data)
python -m ogum_lite.cli segmentation \
  --input exports/derivatives.csv \
  --mode fixed \
  --out artifacts/segments.json

# 6) Detec√ß√£o de mudan√ßa de mecanismo (Œ∏ vs densifica√ß√£o)
python -m ogum_lite.cli mechanism \
  --theta exports/theta_Ea_300kJ.csv \
  --out artifacts/mechanism.csv

# Comandos legados
python -m ogum_lite.cli features --input ...
python -m ogum_lite.cli theta --input ...
python -m ogum_lite.cli msc --input ...
python -m ogum_lite.cli ui
```

O comando `msc` imprime a tabela de m√©tricas (`mse_global`, `mse_segmented`,
`mse_0.55_0.70`, `mse_0.70_0.90`), destaca o melhor Ea e exporta a curva mestra
normalizada.

## Mapas de sinteriza√ß√£o (Blaine n / MSE)

O CLI `maps` gera heatmaps Matplotlib a partir da tabela retornada por
`segment_feature_table`/feature store. Os arquivos `blaine_n_heatmap.png` e
`blaine_mse_heatmap.png` s√£o salvos no diret√≥rio indicado (por padr√£o `maps/`).

```bash
python -m ogum_lite.cli maps \
  --input exports/segment_feature_table.csv \
  --outdir artifacts/maps
```

## API FastAPI + Docker

Suba a API localmente (porta 8000) com auto-reload opcional:

```bash
python -m ogum_lite.cli api --host 0.0.0.0 --port 8000 --reload
```

Os endpoints dispon√≠veis incluem `/prep`, `/features`, `/msc`, `/segmentation`,
`/mechanism`, `/ml/train` e `/ml/predict`. A documenta√ß√£o interativa pode ser
acessada em `http://localhost:8000/docs`.

Para executar via Docker, construa a imagem e exponha a porta da API:

```bash
docker build -t ogum-ml-lite -f docker/Dockerfile .
docker run --rm -p 8000:8000 ogum-ml-lite
```

O container inicia a API automaticamente, permitindo testar os endpoints via
`curl` ou navegando at√© `/docs`.

## Valida√ß√£o de dados

Antes de treinar modelos ou calcular Œ∏(Ea), valide os insumos:

```bash
# Ensaios longos (sample_id,time_s,temp_C,rho_rel/shrinkage_rel)
python -m ogum_lite.cli validate long \
  --input data/ensaios_long.csv \
  --y-col rho_rel \
  --out artifacts/validation_long.json

# Tabela de features derivadas
python -m ogum_lite.cli validate features \
  --table exports/features.csv \
  --out artifacts/validation_features.json
```

O relat√≥rio JSON lista colunas ausentes, valores fora de faixa e percentual de
dados nulos por coluna. No terminal √© impresso um resumo com at√© 10 problemas
para inspe√ß√£o r√°pida.

## Relat√≥rio XLSX consolidado

Monte um relat√≥rio executivo unindo m√©tricas, curva MSC, tabela de features e
imagens (PNG) usando `export xlsx`:

```bash
python -m ogum_lite.cli export xlsx \
  --out reports/ogum_report.xlsx \
  --msc exports/msc_curve.csv \
  --features exports/features.csv \
  --metrics artifacts/cls_technique/model_card.json \
  --dataset "Campanha Ogum 2024" \
  --notes "Resultados finais ap√≥s tuning" \
  --img-msc figures/msc.png \
  --img-cls figures/confusion.png \
  --img-reg figures/regression.png
```

O arquivo final cont√©m abas **Summary**, **MSC**, **Features** e **Metrics** com
metadados (dataset, timestamps, melhores m√©tricas) e imagens opcionais.

## ML (Fase 3)

Os comandos abaixo fecham o ciclo dados ‚Üí features ‚Üí ML com valida√ß√£o
estratificada por `sample_id` (GroupKFold) e artefatos persistidos em disco.

```bash
# 1) Gerar tabela de features (mesma assinatura do comando base)
python -m ogum_lite.cli ml features \
  --input data/ensaios_long.csv \
  --ea "200,300,400" \
  --output exports/features.csv

# 2) Treinar classificador (ex.: t√©cnica de sinteriza√ß√£o)
python -m ogum_lite.cli ml train-cls \
  --table exports/features.csv \
  --target technique \
  --group-col sample_id \
  --features heating_rate_med_C_per_s T_max_C y_final t_to_90pct_s theta_Ea_200kJ theta_Ea_300kJ \
  --outdir artifacts/cls_technique

# 3) Treinar regressor (ex.: T90_C)
python -m ogum_lite.cli ml train-reg \
  --table exports/features.csv \
  --target T90_C \
  --group-col sample_id \
  --features heating_rate_med_C_per_s T_max_C theta_Ea_300kJ theta_Ea_400kJ \
  --outdir artifacts/reg_T90

# 4) Predizer a partir de um artefato salvo
python -m ogum_lite.cli ml predict \
  --table exports/features.csv \
  --model artifacts/cls_technique/classifier.joblib \
  --out exports/preds_cls.csv

# 5) Clusteriza√ß√£o explorat√≥ria (KMeans)
python -m ogum_lite.cli ml cluster \
  --table exports/features.csv \
  --features heating_rate_med_C_per_s T_max_C theta_Ea_300kJ \
  --k 3 \
  --out exports/clusters.csv
```

Durante o treino s√£o impressas as m√©tricas m√©dias/desvio obtidas via
`GroupKFold`, garantindo que nenhuma amostra (`sample_id`) aparece em m√∫ltiplos
folds. Os artefatos exportados incluem `.joblib`, `feature_cols.json`,
`target.json` e `model_card.json` com timestamp, hiperpar√¢metros e m√©tricas.

Targets can√¥nicos compat√≠veis com Ogum 6.4:

| Tarefa           | Coluna alvo            |
|------------------|------------------------|
| Classifica√ß√£o    | `technique` (Conventional, UHS, FS, SPS, ‚Ä¶) |
| Regress√£o        | `T90_C`, `rho_final`, `Ea_app_kJmol`        |

As features geradas automaticamente incluem m√©tricas globais
(`heating_rate_med_C_per_s`, `T_max_C`, `y_final`, `t_to_90pct_s`, `dy_dt_max`,
`dT_dt_max`, `T_at_dy_dt_max_C`), colunas segmentadas (`*_s1`, `*_s2`) e Ea
Arrhenius (`Ea_arr_global_kJ`, `Ea_arr_55_70_kJ`, ‚Ä¶), al√©m das integrais
`theta_Ea_*` quando solicitadas.

## Tuning & Reports (Fase 4)

Novos comandos do grupo `ml` completam o ciclo **train ‚Üí tune ‚Üí explicar ‚Üí
documentar** com artefatos prontos para revis√£o:

```bash
# RandomizedSearchCV para classifica√ß√£o (RandomForest + GroupKFold)
python -m ogum_lite.cli ml tune-cls \
  --table exports/features.csv \
  --target technique \
  --group-col sample_id \
  --features heating_rate_med_C_per_s T_max_C theta_Ea_300kJ theta_Ea_400kJ \
  --outdir artifacts/cls_technique \
  --n-iter 40 --cv 5

# RandomizedSearchCV para regress√£o (RandomForestRegressor)
python -m ogum_lite.cli ml tune-reg \
  --table exports/features.csv \
  --target T90_C \
  --group-col sample_id \
  --features heating_rate_med_C_per_s T_max_C theta_Ea_300kJ theta_Ea_400kJ \
  --outdir artifacts/reg_T90 \
  --n-iter 40 --cv 5

# Relat√≥rio HTML com m√©tricas, gr√°ficos e model card atualizado
python -m ogum_lite.cli ml report \
  --table exports/features.csv \
  --target technique \
  --group-col sample_id \
  --model artifacts/cls_technique/classifier_tuned.joblib \
  --outdir artifacts/cls_technique \
  --notes "Resultados validados em 2024-05"
```

Cada execu√ß√£o cria/atualiza os artefatos em `outdir`:

- `*_tuned.joblib`: pipeline completo com pr√©-processamento e melhor estimador;
- `param_grid.json` + `cv_results.json`: espa√ßo de busca e resultados da busca;
- `model_card.json`: inclui hist√≥rico (`history`) com tuning, `best_params` e
  m√©tricas m√©dias (accuracy/F1 ou MAE/RMSE);
- `feature_importance.png`, `confusion_matrix.png`/`regression_scatter.png` e
  `report.html` com m√©tricas, figuras embutidas (base64) e observa√ß√µes.

Checklist r√°pido de boas pr√°ticas:

1. **GroupKFold obrigat√≥rio**: sempre informar `--group-col sample_id` para
   evitar vazamento entre ensaios do mesmo corpo de prova.
2. **Features limpas**: garantir que `feature_cols.json` reflita exatamente as
   colunas usadas; o comando de tuning atualiza o arquivo automaticamente.
3. **Relat√≥rios versionados**: utilize `--notes` para registrar contexto
   (experimento, data, analista) direto no `report.html` e no `model_card`.
4. **Reprodutibilidade**: fixe `--random-state` quando comparar execu√ß√µes ou
   compartilhar notebooks/artefatos com terceiros.

## Docker

Para empacotar a CLI/UI em um cont√™iner leve:

```bash
docker build -t ogum-ml:latest -f docker/Dockerfile .
docker run --rm -v "$PWD":/work ogum-ml:latest --help
```

O cont√™iner inicia com `python -m ogum_lite.cli` como entrypoint; basta montar o
diret√≥rio com dados e escolher o subcomando desejado (`ui`, `msc`, `ml ...`).

## Release e distribui√ß√£o

O workflow `release.yml` empacota a wheel e publica ativos extras sempre que uma
tag `v*` √© enviada ao reposit√≥rio remoto:

```bash
git tag v0.2.0
git push origin v0.2.0
```

Al√©m da wheel (`dist/*.whl`), arquivos em `artifacts/**` s√£o anexados √† Release.

## Export ONNX (opcional)

Para gerar modelos compat√≠veis com infer√™ncia embarcada, instale as depend√™ncias
opcionais e use o novo comando:

```bash
pip install skl2onnx onnxmltools

python -m ogum_lite.cli export onnx \
  --model artifacts/cls_technique/classifier_tuned.joblib \
  --features-json artifacts/cls_technique/feature_cols.json \
  --out artifacts/cls_technique/model.onnx
```

Se as depend√™ncias n√£o estiverem instaladas ou o estimador n√£o for um
`RandomForest*`, o comando √© ignorado com um aviso (c√≥digo de sa√≠da 0).

## Fluxo em Colab

1. Abra o notebook de exemplo clicando no badge **Open In Colab** acima ou no
   novo `notebooks/ogum_ml_derivatives_demo.ipynb`.
2. Execute a primeira c√©lula para mapear a planilha e gerar `derivatives.csv`.
3. Use as c√©lulas seguintes para obter `arrhenius.csv`, `feature_store.csv` e a
   curva MSC.
4. Opcional: rode `python -m ogum_lite.cli ui` em uma c√©lula para acessar a UI
   interativa com mapeamento assistido.

## Integra√ß√£o com Ogum 6.4

- Mesma nomenclatura de colunas e est√°gios.
- Resultados (Œ∏(Ea) e MSC) podem ser exportados em CSV para ingest√£o no Ogum 6.4.
- Futuras vers√µes utilizar√£o `ml_hooks` para acoplamento com pipelines
  existentes do Ogum e notebooks do reposit√≥rio ogumsoftware.

## Desenvolvimento

Executar checagens locais antes de enviar contribui√ß√µes:

```bash
ruff check .
black --check .
pytest -q
```

CI via GitHub Actions executa o mesmo pipeline de lint e testes.

## Estrutura

```
ogum_lite/
  cli.py          # CLI com subcomandos features, theta, msc, ui e ml/*
  features.py     # Engenharia de atributos por amostra
  ml_hooks.py     # Pipelines sklearn (classifica√ß√£o, regress√£o, cluster)
  theta_msc.py    # Œ∏(Ea), Master Sintering Curve e m√©tricas robustas
artifacts/        # Diret√≥rio sugerido para modelos e relat√≥rios de ML
notebooks/
  ogum_ml_demo.ipynb       # Fluxo m√≠nimo Œ∏(Ea)/MSC em Colab
  ogum_ml_ml_demo.ipynb    # Exemplo end-to-end de ML (Fase 3)
tests/
  test_features.py, test_msc.py, test_ml_pipeline.py, test_smoke.py
```

## Roadmap (ml_hooks)

- Registrar pipelines de classifica√ß√£o/regress√£o (`register_pipeline`).
- Carregar modelos treinados (joblib/MLflow) via `load_pipeline`.
- Padronizar contratos de entrada/sa√≠da para integra√ß√£o com Ogum completo.
